import json
import os
import pandas as pd
import numpy as np

from tqdm import tqdm, tqdm_notebook
from enum import Enum
from shapely.geometry import Polygon, box
from skimage.draw import polygon as Skpolygon
from odin.classes import DatasetClassification, TaskType
from odin.classes.strings import err_type
from odin.utils import get_root_logger
from odin.utils.env import is_notebook
from odin.utils.lazy_dictionary import LazyDict

logger = get_root_logger()


class AnnotationType(Enum):
    BBOX = 0
    SEGMENTATION = 1


class DatasetCAMs(DatasetClassification):

    def __init__(self,
                 dataset_gt_param,
                 task_type,
                 cams_paths=None,
                 annotation_type=AnnotationType.BBOX,
                 proposals_paths=None,
                 observations_set_name='test',
                 observations_abs_path=None,
                 result_saving_path='./results/',
                 similar_classes=None,
                 properties_file=None,
                 for_analysis=True,
                 load_properties=True,
                 match_on_filename=False,
                 save_graphs_as_png=True):
        """
        The DatasetCAMs class can be used to store the ground truth and the Class Activation Maps generated by classification models.

        Parameters
        ----------
        dataset_gt_param: str
            Path of the ground truth .json file.
        task_type: TaskType
            Problem task type. It can be: TaskType.CLASSIFICATION_BINARY, TaskType.CLASSIFICATION_SINGLE_LABEL, TaskType.CLASSIFICATION_MULTI_LABEL.
        cams_paths: list of tuple, optional
            List of couples. Each couple contains the model name and the corresponding CAMs path. (default is None)
        annotation_type: AnnotationType, optional
            Indicates whether the annotation is a bounding box (AnnotationType.BBOX) or a segmentation mask (AnnotationType.SEGMENTATION). (default is AnnotationType.BBOX)"
        proposals_paths: list of tuple, optional
            List of couples. Each couple contains the model name and the corresponding proposals path. (default is None)
        observations_set_name: str, optional
            Name of the data set. (default is 'test')
        observations_abs_path: str, optional
            Path of the observation directory. (default is None)
        result_saving_path: str, optional
            Path used to save results. (default is './results/')
        similar_classes: list of list, optional
            List of groups of ids of categories which are similar to each other. (default is None)
        properties_file: str, optional
            The name of the file used to store the names of and values of the properties and the names of the categories. (default is 'properties.json')
        for_analysis: bool, analysis
            Indicates whether the properties and the predictions have to be loaded. If False, only the ground truth is loaded. (default is True)
        load_properties: bool, optional
            Indicates whether the properties should be loaded. (default is True)
        match_on_filename: bool, optional
            Indicates whether the predictions refer to the ground truth by file_name< (set to True) or by id< (set to False). (default is False)
        save_graphs_as_png: bool, optional
            Indicates whether plots should be saved as .png images. (default is True)
        """
        if cams_paths is not None:
            if isinstance(cams_paths, str):
                cams_paths = [("model", cams_paths)]
            elif (not isinstance(cams_paths, list) or
                  not all(isinstance(c, tuple) for c in cams_paths) or
                  not all(isinstance(n, str) and isinstance(p, str) for n, p in cams_paths)):
                raise TypeError(err_type.format("cams_paths"))
        if not isinstance(annotation_type, AnnotationType):
            raise TypeError(err_type.format("annotation_type"))

        self.cams_paths = cams_paths
        self.ann_type = annotation_type
        self.cams = {}
        self.gt_masks = None

        self.__tqdm = tqdm_notebook if is_notebook() else tqdm
        super().__init__(dataset_gt_param, task_type, proposals_paths, observations_set_name, observations_abs_path,
                         result_saving_path, similar_classes, properties_file, for_analysis, load_properties,
                         match_on_filename, save_graphs_as_png)

    def __from_coco_coordinates_to_polygon(self, coco_coords):
        """From array in format [x1,y1,x2,y2,...,xn,yn]
        to [[x1,y1],[x2,y2],...,[xn,yn]] and then to Polygon"""
        coords_arr = [[int(coco_coords[i]), int(coco_coords[i + 1])] for i in range(0, len(coco_coords), 2)]
        poly = Polygon(coords_arr)
        return poly

    def __from_coco_bbox_to_box_object(self, coco_coords):
        """From coco coordinates in format [x_distance, y_distance, width, height]
        to shapely box object
        """
        b = box(coco_coords[0], coco_coords[1], coco_coords[2] + coco_coords[0], coco_coords[3] + coco_coords[1])
        return b

    def __update_mask_from_polygons(self, mask, polygons):
        """
        Update the gt mask from the polygon shape
        Parameters
        ----------
        mask: np.array
        polygons: Skpolygon
        """
        for poly in polygons:
            poly_coordinates = np.array(list(poly.exterior.coords))
            rr, cc = Skpolygon(poly_coordinates[:, 1], poly_coordinates[:, 0], (mask.shape[0], mask.shape[1]))
            mask[rr, cc] = 1

    def _load_cams(self, img_ids, file_names, categories_ids, model_name, path):
        """
        Returns a DataFrame that contains for each image-category couple the corresponding CAM
        Parameters
        ----------
        img_ids: list
            Ids of the images
        file_names: list
            Names of the .npy files to be loaded
        categories_ids: list
            Ids of the categories

        Returns
        -------
            DataFrame
        """
        print("Loading CAMs of {} model...".format(model_name))
        try:
            cams = []
            counter = 0
            for img_id, file_name in self.__tqdm(zip(img_ids, file_names), total=len(img_ids)):
                cam_filename = file_name.split(".")[0] + ".npy"
                full_path = os.path.join(path, cam_filename)

                if not os.path.exists(full_path):
                    logger.warning("Path not found: {}".format(full_path))
                    continue
                cams_file = np.load(full_path, allow_pickle=True)
                if cams_file.shape[0] != len(self.categories):
                    logger.warning("Invalid number of cams for file '{}'. Expected: {}, Actual: {}".format(
                        file_name, len(self.categories), cams_file.shape[0]))
                    continue
                for idx, cat_id in enumerate(categories_ids):
                    counter += 1
                    cam = {"id": counter, "image_id": img_id, "category_id": cat_id, "cam": cams_file[idx]}
                    cams.append(cam)
        except:
            raise Exception("Error loading CAMs of {} model".format(model_name))

        print("Done!")
        return pd.DataFrame(cams)

    def _load_gt(self, img_ids, annotations):
        """
        Returns a DataFrame that contains for each category-image pair the global mask and the component masks
        Parameters
        ----------
        img_ids: list
            Ids of the images to be loaded
        annotations: DataFrame
            Gt annotations

        Returns
        -------
            DataFrame
        """
        gt = []
        counter = 0
        for id in self.__tqdm(img_ids):
            img = self.observations.loc[self.observations["id"] == id]
            height, width = img["height"].values[0], img["width"].values[0]
            img_annotations = annotations.loc[annotations["image_id"] == id].copy()
            if self.ann_type == AnnotationType.BBOX:
                img_annotations["polygon"] = img_annotations["bbox"].apply(lambda x: self.__from_coco_bbox_to_box_object(x))
            else:
                img_annotations["polygon"] = img_annotations["segmentation"].apply(
                    lambda x: self.__from_coco_coordinates_to_polygon(x[0]))
            annotations_groups = img_annotations.groupby("category_id")
            for cat_id, group in annotations_groups:
                global_mask = np.zeros((1, height, width), dtype=np.uint8)
                masks = []
                bboxes = []
                for idx, row in group.iterrows():
                    mask = np.zeros((1, height, width), dtype=np.uint8)
                    self.__update_mask_from_polygons(mask[0], [row["polygon"]])
                    if mask.sum() > 1:
                        masks.append(mask)
                        global_mask = np.bitwise_or(global_mask, mask)
                        bboxes.append(row["bbox"])
                global_mask = global_mask[0]
                counter += 1
                gt_mask = {"id": counter, "image_id": id, "category_id": cat_id, "masks": masks,
                           "global_mask": global_mask}
                gt.append(gt_mask)
        return pd.DataFrame(gt)

    def load(self, force_loading=False, load_properties=True):
        """
        Loads the dataset, the proposals and the properties into memory

        Parameters
        ----------
        force_loading: bool, optional
            If True reload the dataset and the proposals
        """
        try:
            if force_loading or self.observations is None:
                print("Loading dataset...")

                file = open(self.dataset_root_param, "r")
                data = json.load(file)
                file.close()
                self.observations = pd.DataFrame(data['observations'])
                self.categories = pd.DataFrame(data["categories"])
                self.masks_annotations = pd.DataFrame(data["annotations"])

                self._is_valid_dataset_format()

                print("Done!")

        except:
            raise Exception("Error loading dataset")

        try:
            if force_loading or self.gt_masks is None:
                print("Loading CAMs annotations...")
                self.gt_masks = self._load_gt(self.observations["id"].tolist(), self.masks_annotations)
                print("Done!")
        except:
            raise Exception("Error loading CAMs annotations.")

        if not self.for_analysis:
            self._index_gt()
            self._analyses_without_properties_available = True
            return

        if self.cams_paths is not None:
            if force_loading or not self.cams:
                self.load_cams()

        if self.proposals_paths is not None:
            if force_loading or not self.proposals:
                self.load_proposals()

        if not load_properties:
            self._index_gt()
            try:
                if not os.path.exists(self.properties_filename) or not self._is_properties_file_valid(None, None, False):
                    self._create_properties([], None)
            except:
                self._create_properties([], None)
            self.load_categories_display_names()
            self._analyses_without_properties_available = True
            return

        if is_notebook():
            self._load_or_create_properties_notebook(self.observations,
                                                     self.common_properties,
                                                     self._set_analyses_with_properties_available)
        else:
            self._load_or_create_properties(self.observations,
                                            self.common_properties)
            self._set_analyses_with_properties_available()

    def load_cams(self):
        tmp_dict = {}
        for model_name, path in self.cams_paths:
            observations = self.get_all_observations()
            categories_id_from_names = self.get_categories_id_from_names(self.get_categories_names())
            tmp_dict[model_name] = (self._load_cams, observations["id"].tolist(), observations["file_name"].tolist(),
                                    categories_id_from_names, model_name, path)
        self.cams = LazyDict(tmp_dict)

    def get_cams_for_images_ids(self, images_ids, model_name):
        if self.cams and model_name in self.cams:
            return self.cams[model_name].loc[self.cams[model_name]["image_id"].isin(images_ids)]

    def get_cams_for_images_ids_and_category(self, images_ids, category_id, model_name):
        """
        Returns the CAMs of a specific category and that refer to specific images
        Parameters
        ----------
        images_ids: list
            List of images ids
        category_id: int
            Category id

        Returns
        -------
            DataFrame
        """
        if self.cams and model_name in self.cams:
            return self.cams[model_name].loc[(self.cams[model_name]["image_id"].isin(images_ids)) &
                                             (self.cams[model_name]["category_id"] == category_id)]

    def get_gt_masks_for_category(self, category_id):
        """
        Return all the gt masks of a specific category
        Parameters
        ----------
        category_id: int
            Category id

        Returns
        -------
            DataFrame
        """
        if self.gt_masks is not None:
            return self.gt_masks.loc[self.gt_masks["category_id"] == category_id]

    def get_gt_masks_for_images_ids_and_category(self, images_ids, category_id):
        """
        Returns the gt masks of a specific category and that refer to specific images
        Parameters
        ----------
        images_ids: list
            List of images ids
        category_id: int
            Category id

        Returns
        -------
            DataFrame
        """
        if self.gt_masks is not None:
            return self.gt_masks.loc[(self.gt_masks["image_id"].isin(images_ids)) &
                                     (self.gt_masks["category_id"] == category_id)]
