{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351e3d5c",
   "metadata": {},
   "source": [
    "# Example of model analysis for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e92ead",
   "metadata": {},
   "source": [
    "#### package import and variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from odin.classes import Curves\n",
    "from odin.classes.timeseries import StandardScaler\n",
    "from odin.classes.timeseries.anomaly_definition_strategies import AnomalyDefinitionStrategyTSAE\n",
    "from odin.classes.timeseries.anomaly_matching_strategies import *\n",
    "from odin.classes.timeseries import DatasetTSAnomalyDetection, TimeSeriesType, TSProposalsType, AnalyzerTSAnomalyDetection\n",
    "from odin.classes import Errors, Metrics, CustomError, ErrCombination\n",
    "from odin.classes.timeseries.metrics import f1_score\n",
    "from odin.classes.timeseries.ts_custom_metric import TSCustomMetric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b6c6e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75156e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(mean=71.43390471202335, std=4.612135080923405)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658af5ef",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_PATH = \"../../test-data/anomaly_detection/gt.csv\"\n",
    "PROPOSALS_PATH = [('LSTM', \"../../test-data/anomaly_detection/predictions.csv\", TSProposalsType.REGRESSION)]\n",
    "\n",
    "my_dataset = DatasetTSAnomalyDetection(GT_PATH,\n",
    "                                       TimeSeriesType.UNIVARIATE,\n",
    "                                       anomalies_path='../../test-data/anomaly_detection/anomalies.json',\n",
    "                                       proposals_paths=PROPOSALS_PATH, \n",
    "                                       properties_path='../../test-data/anomaly_detection/properties.csv',\n",
    "                                       index_gt='timestamp', \n",
    "                                       index_proposals='timestamp',\n",
    "                                       scaler=scaler\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeecf336",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.get_observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae83a8",
   "metadata": {},
   "source": [
    "#### Inspect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.get_aggregate_anomalies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.get_anomaly_percentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23745580",
   "metadata": {},
   "source": [
    "#### Data set analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.analyze_stationarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.analyze_periodicity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80397d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_dataset.analyze_seasonality_trend(period=24*7*2, model_type='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6c132",
   "metadata": {},
   "source": [
    "### Property distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78299f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_property(property_name=\"my_meta_ann\",\n",
    "                                         plot_type=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f697253",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create the anomaly strategy evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5911ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = AnomalyDefinitionStrategyTSAE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea1257",
   "metadata": {},
   "source": [
    "## Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b265590",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer = AnalyzerTSAnomalyDetection('LSTM', \n",
    "                                         my_dataset, \n",
    "                                         threshold=0.85, #1.6\n",
    "                                         anomaly_evaluation=evaluator,\n",
    "                                         #matching_strategy=AnomalyMatchingStrategyIntervalToInterval(0.01),\n",
    "                                         scaler_values=(True, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d278b4",
   "metadata": {},
   "source": [
    "### Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a468ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_performance_for_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e03d05",
   "metadata": {},
   "source": [
    "### False Positive errors analysis\n",
    "FP errors are categorized into \"generic\", \"affected\", and \"continuous\", and then their distance distribution from the nearest anomaly is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec226a8d",
   "metadata": {},
   "source": [
    "#### Combine predefined errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15865c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anticipation = ErrCombination(\"ANTICIPATION\", \n",
    "                              [Errors.BEFORE, Errors.CLOSELY_BEFORE, Errors.CLOSELY_AFTER, Errors.AFTER], \n",
    "                              [\"Before\", \"Closely before\", \"Closely after\", \"After\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d13a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_errors(metric = Metrics.ACCURACY, \n",
    "                                          error_combination = anticipation, \n",
    "                                          parameters_dicts = [{'closely_threshold': 410}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ca82d",
   "metadata": {},
   "source": [
    "#### Combine custom errors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f4dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAC(CustomError):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def compute_error(self, y_true, y_score, threshold, observations, parameters_dict = None):\n",
    "        distance = parameters_dict['distance']\n",
    "    \n",
    "        y_pred = np.where(y_score >= threshold, 1, 0)\n",
    "\n",
    "        matching = pd.DataFrame(data={'y_true': y_true,\n",
    "                                      'y_pred': y_pred},\n",
    "                                index=observations.index)\n",
    "        matching['eval'] = 0\n",
    "        matching.loc[matching['y_true'] == 1, 'eval'] = 1\n",
    "        matching.loc[(matching['y_true'] == 0) & (matching['y_pred'] == 1), 'eval'] = -1\n",
    "\n",
    "        generic, affected, continuous = 0, 0, 0\n",
    "\n",
    "        anomalies_pos = np.where(matching['eval'] == 1)[0]\n",
    "\n",
    "        previous_anomaly_pos = -1\n",
    "        anomaly_pos_index = 0\n",
    "        next_anomaly_pos = anomalies_pos[0]\n",
    "        is_previous_anomaly = False\n",
    "        is_next_anomaly = False\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        index_values = matching.index\n",
    "        errors_index = []\n",
    "\n",
    "        for i, v in enumerate(matching['eval'].values):\n",
    "            if (i > next_anomaly_pos) and (next_anomaly_pos != -1):\n",
    "                previous_anomaly_pos = next_anomaly_pos\n",
    "                anomaly_pos_index += 1\n",
    "                next_anomaly_pos = anomalies_pos[anomaly_pos_index] if anomaly_pos_index < len(anomalies_pos) else -1\n",
    "            is_next_anomaly = False\n",
    "            if i < len(matching)-1 and matching['y_pred'].values[i+1] == 1:\n",
    "                is_next_anomaly = True\n",
    "            if v == -1:\n",
    "                previous_d = i - previous_anomaly_pos if previous_anomaly_pos != -1 else float('inf')\n",
    "                next_d = i - next_anomaly_pos if next_anomaly_pos != -1 else float('inf')\n",
    "\n",
    "                d = previous_d if previous_d < np.abs(next_d) else next_d\n",
    "                # AFFECTED errors\n",
    "                if np.abs(d) <= distance:\n",
    "                    affected += 1\n",
    "                    distances.append(d)\n",
    "                    errors_index.append(index_values[i])\n",
    "               \n",
    "\n",
    "                is_previous_anomaly = True\n",
    "\n",
    "            else:\n",
    "                is_previous_anomaly = False\n",
    "\n",
    "        return affected, distances, errors_index, matching\n",
    "    \n",
    "affected = GAC(\"affected\")\n",
    "\n",
    "class GAC(CustomError):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def compute_error(self, y_true, y_score, threshold, observations, parameters_dict = None):\n",
    "        distance = parameters_dict['distance']\n",
    "    \n",
    "        y_pred = np.where(y_score >= threshold, 1, 0)\n",
    "\n",
    "        matching = pd.DataFrame(data={'y_true': y_true,\n",
    "                                      'y_pred': y_pred},\n",
    "                                index=observations.index)\n",
    "        matching['eval'] = 0\n",
    "        matching.loc[matching['y_true'] == 1, 'eval'] = 1\n",
    "        matching.loc[(matching['y_true'] == 0) & (matching['y_pred'] == 1), 'eval'] = -1\n",
    "\n",
    "        generic, affected, continuous = 0, 0, 0\n",
    "\n",
    "        anomalies_pos = np.where(matching['eval'] == 1)[0]\n",
    "\n",
    "        previous_anomaly_pos = -1\n",
    "        anomaly_pos_index = 0\n",
    "        next_anomaly_pos = anomalies_pos[0]\n",
    "        is_previous_anomaly = False\n",
    "        is_next_anomaly = False\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        index_values = matching.index\n",
    "        errors_index = []\n",
    "\n",
    "        for i, v in enumerate(matching['eval'].values):\n",
    "            if (i > next_anomaly_pos) and (next_anomaly_pos != -1):\n",
    "                previous_anomaly_pos = next_anomaly_pos\n",
    "                anomaly_pos_index += 1\n",
    "                next_anomaly_pos = anomalies_pos[anomaly_pos_index] if anomaly_pos_index < len(anomalies_pos) else -1\n",
    "            is_next_anomaly = False\n",
    "            if i < len(matching)-1 and matching['y_pred'].values[i+1] == 1:\n",
    "                is_next_anomaly = True\n",
    "            if v == -1:\n",
    "                previous_d = i - previous_anomaly_pos if previous_anomaly_pos != -1 else float('inf')\n",
    "                next_d = i - next_anomaly_pos if next_anomaly_pos != -1 else float('inf')\n",
    "\n",
    "                d = previous_d if previous_d < np.abs(next_d) else next_d\n",
    "                # CONTINUOUS errors\n",
    "                if np.abs(d) > distance and (is_previous_anomaly or is_next_anomaly):\n",
    "                    continuous += 1\n",
    "                    distances.append(d)\n",
    "                    errors_index.append(index_values[i])\n",
    "               \n",
    "\n",
    "                is_previous_anomaly = True\n",
    "\n",
    "            else:\n",
    "                is_previous_anomaly = False\n",
    "\n",
    "        return continuous, distances, errors_index, matching\n",
    "    \n",
    "    \n",
    "continuous = GAC(\"continuous\")\n",
    "\n",
    "\n",
    "class GAC(CustomError):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def compute_error(self, y_true, y_score, threshold, observations, parameters_dict = None):\n",
    "        distance = parameters_dict['distance']\n",
    "    \n",
    "        y_pred = np.where(y_score >= threshold, 1, 0)\n",
    "\n",
    "        matching = pd.DataFrame(data={'y_true': y_true,\n",
    "                                      'y_pred': y_pred},\n",
    "                                index=observations.index)\n",
    "        matching['eval'] = 0\n",
    "        matching.loc[matching['y_true'] == 1, 'eval'] = 1\n",
    "        matching.loc[(matching['y_true'] == 0) & (matching['y_pred'] == 1), 'eval'] = -1\n",
    "\n",
    "        generic, affected, continuous = 0, 0, 0\n",
    "\n",
    "        anomalies_pos = np.where(matching['eval'] == 1)[0]\n",
    "\n",
    "        previous_anomaly_pos = -1\n",
    "        anomaly_pos_index = 0\n",
    "        next_anomaly_pos = anomalies_pos[0]\n",
    "        is_previous_anomaly = False\n",
    "        is_next_anomaly = False\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        index_values = matching.index\n",
    "        errors_index = []\n",
    "\n",
    "        for i, v in enumerate(matching['eval'].values):\n",
    "            if (i > next_anomaly_pos) and (next_anomaly_pos != -1):\n",
    "                previous_anomaly_pos = next_anomaly_pos\n",
    "                anomaly_pos_index += 1\n",
    "                next_anomaly_pos = anomalies_pos[anomaly_pos_index] if anomaly_pos_index < len(anomalies_pos) else -1\n",
    "            is_next_anomaly = False\n",
    "            if i < len(matching)-1 and matching['y_pred'].values[i+1] == 1:\n",
    "                is_next_anomaly = True\n",
    "            if v == -1:\n",
    "                previous_d = i - previous_anomaly_pos if previous_anomaly_pos != -1 else float('inf')\n",
    "                next_d = i - next_anomaly_pos if next_anomaly_pos != -1 else float('inf')\n",
    "\n",
    "                d = previous_d if previous_d < np.abs(next_d) else next_d\n",
    "                # GENERIC errors\n",
    "                if np.abs(d) > distance and not (is_previous_anomaly or is_next_anomaly):\n",
    "                    generic += 1\n",
    "                    distances.append(d)\n",
    "                    errors_index.append(index_values[i])\n",
    "               \n",
    "\n",
    "                is_previous_anomaly = True\n",
    "\n",
    "            else:\n",
    "                is_previous_anomaly = False\n",
    "\n",
    "        return generic, distances, errors_index, matching\n",
    "    \n",
    "generic = GAC(\"generic\")\n",
    "\n",
    "gac = ErrCombination(\"GAC\", \n",
    "                     [affected, continuous, generic], \n",
    "                     [\"Affected\", \"Continuous\", \"Generic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab55409",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_errors(metric = Metrics.F1_SCORE, \n",
    "                                          error_combination = gac,\n",
    "                                          parameters_dicts = [{'distance': 300}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e010cb",
   "metadata": {},
   "source": [
    "### Reliability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77687e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_reliability(min_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_gain_lift()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ffaf6",
   "metadata": {},
   "source": [
    "### Predicted and GT windows duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfee46e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_true_predicted_distributions(groups=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4ce49",
   "metadata": {},
   "source": [
    "### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59daec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_curve(Curves.ROC_CURVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_curve(Curves.PRECISION_RECALL_CURVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e0a17",
   "metadata": {},
   "source": [
    "### Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomF1(TSCustomMetric):\n",
    "    def __init__(self, name, is_single_threshold):\n",
    "        super().__init__(name, is_single_threshold)\n",
    "\n",
    "    def evaluate_metric(self, y_true,\n",
    "                        y_pred,\n",
    "                        threshold = None,\n",
    "                        inverse_threshold = False,\n",
    "                        evaluation_type = None,\n",
    "                        min_consecutive_samples = 1):\n",
    "        return f1_score(y_true, y_pred, threshold, evaluation_type, inverse_threshold, min_consecutive_samples)\n",
    "\n",
    "my_custom_metric = MyCustomF1(\"CUSTOM_F1\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbe780",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.add_custom_metric(my_custom_metric)\n",
    "my_analyzer.analyze_performance(metrics=[Metrics.F1_SCORE, Metrics.CUSTOM_F1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83cf83",
   "metadata": {},
   "source": [
    "## Analyzer with matching strategy interval-interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer = AnalyzerTSAnomalyDetection('LSTM', \n",
    "                                         my_dataset, \n",
    "                                         threshold=1.6,\n",
    "                                         anomaly_evaluation=evaluator,\n",
    "                                         matching_strategy=AnomalyMatchingStrategyIntervalToInterval(0.01),\n",
    "                                         scaler_values=(True, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adea4d8",
   "metadata": {},
   "source": [
    "### Predicted and GT windows duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6327759",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_true_predicted_difference_distribution(nbins=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3005ae",
   "metadata": {},
   "source": [
    "### IOU Analysis on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc283f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_performance_for_iou_threshold(granularity=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cbac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_iou_distribution(nbins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb10eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46a3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
