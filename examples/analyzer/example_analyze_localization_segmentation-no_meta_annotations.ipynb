{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of model analysis for instance segmentation\n",
    "# NO META-ANNOTATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### package import and variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odin.classes import DatasetLocalization, AnalyzerLocalization, Metrics, TaskType, Curves\n",
    "\n",
    "# define the path of the GT .json file\n",
    "dataset_gt_param = \"../../test-data/localization/gt.json\"\n",
    "\n",
    "# define the path of the folder that contains the predictions .txt files\n",
    "path_to_detections = [(\"Model_A\", \"../../test-data/localization/predictions-segmentation/\")]\n",
    "\n",
    "# define the problem task (INSTANCE_SEGMENTATION, OBJECT_DETECTION)\n",
    "task_type = TaskType.INSTANCE_SEGMENTATION\n",
    "\n",
    "# [OPTIONAL] define the file_name for the categories\n",
    "properties_file = \"categories_plane.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = DatasetLocalization(dataset_gt_param, \n",
    "                                 task_type, \n",
    "                                 proposals_paths=path_to_detections, \n",
    "                                 properties_file=properties_file, \n",
    "                                 save_graphs_as_png=False,\n",
    "                                 for_analysis=True,\n",
    "                                 load_properties=False # IMPORTANT\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available dataset explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.show_co_occurrence_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_categories()\n",
    "\n",
    "# [OPTIONAL] do not compute also the avg size of the mask/bbox for each category\n",
    "# show_avg_size = False\n",
    "\n",
    "# my_dataset.show_distribution_of_categories(show_avg_size=show_avg_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer = AnalyzerLocalization('Model_A', # N.B. the name must be the same of ones in the list of the proposals \n",
    "                                   my_dataset, \n",
    "                                   use_normalization=True,\n",
    "                                   norm_factor_categories=0.3, \n",
    "                                   metric=Metrics.AVERAGE_PRECISION_INTERPOLATED,\n",
    "                                   save_graphs_as_png=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load custom display names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you change the display names of the categories in the properties file\n",
    "my_dataset.load_categories_display_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.set_normalization(True, with_properties=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positives errors analysis\n",
    "For each category, FP errors are categorized into \"similar\", \"background\", \"localization\", and \"other\", and the impact of each type of error on the evaluation metric score is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_errors()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_false_positive_errors(categories=categories, metric=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_errors_for_category('SmallCivilTransportUtility')\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_false_positive_errors_for_category('SmallCivilTransportUtility', metric=eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False negatives errors analysis\n",
    "For each category, FN errors are categorized into \"similar\", \"localization\",  \"no_prediction\", and \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_negative_errors()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.analyze_false_negative_errors(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_negative_errors_for_category(\"LargeCivilTransportUtility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis based on PR curve and F1 curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_curve()\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis (default is PRECISION_RECALL_CURVE)\n",
    "# eval_curve = Curves.F1_CURVE \n",
    "\n",
    "# [OPTIONAL] set the averaging method to be used in the analysis (default is \"macro\")\n",
    "# avg_method = \"micro\"\n",
    "\n",
    "# my_analyzer.analyze_curve(curve=eval_curve, average=avg_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_curve_for_categories()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis (default is PRECISION_RECALL_CURVE)\n",
    "# eval_curve = Curves.F1_CURVE \n",
    "\n",
    "# my_analyzer.analyze_curve_for_categories(categories=categories, curve=eval_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis based on IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_intersection_over_union()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_intersection_over_union(categories=categories, metric=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_intersection_over_union_for_category('SmallCivilTransportUtility')\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_intersection_over_union_for_category('SmallCivilTransportUtility', metric=eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_reliability()\n",
    "\n",
    "# [OPTIONAL] define the number of bins for the analysis (default is 10)\n",
    "# bins = 20\n",
    "\n",
    "# my_analyzer.analyze_reliability(categories=categories, num_bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_reliability_for_categories()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] define the number of bins for the analysis (default is 10)\n",
    "# bins = 20\n",
    "\n",
    "# my_analyzer.analyze_reliability_for_categories(categories=categories, num_bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP, FP, FN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_true_positive_distribution()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_true_positive_distribution(categories=categories)\n",
    "\n",
    "#my_analyzer.show_true_positive_distribution(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_false_negative_distribution()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_false_negative_distribution(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_false_positive_distribution()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_false_positive_distribution(categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report of all the performance at all levels of granularity (overall, per-category, per-meta-annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.base_report(show_properties=False)\n",
    "\n",
    "# [OPTIONAL] define specific evaluation metrics to be included in the report\n",
    "# eval_metrics = [Metrics.PRECISION_SCORE, Metrics.F1_SCORE]\n",
    "\n",
    "# [OPTIONAL] define specific categories to be included in the report\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] define specific meta-annotations to be included in the report\n",
    "# meta_annotations = [\"weather\", \"wing_type\"]\n",
    "\n",
    "# [OPTIONAL] do not include categories and/or meta-annotations in the report\n",
    "# show_categories = False\n",
    "# show_meta_annotations = False\n",
    "\n",
    "# # [OPTIONAL] do not include reliability ECE and MCE in the report\n",
    "# include_reliability=False\n",
    "\n",
    "# my_analyzer.base_report(metrics=eval_metrics, categories=categories, properties=meta_annotations, show_categories=show_categories, show_properties=show_meta_annotations, include_reliability=include_reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
