{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of model analysis for instance segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### package import and variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from odin.classes import DatasetLocalization, AnalyzerLocalization, Metrics, TaskType, Curves\n",
    "\n",
    "# define the path of the GT .json file\n",
    "dataset_gt_param = \"../../test-data/localization/gt.json\"\n",
    "\n",
    "# define the path of the folder that contains the predictions .txt files for each model\n",
    "path_to_detections = \"../../test-data/localization/predictions-segmentation/\"\n",
    "# path_to_detections = [(\"Model_A\", \"../../test-data/localization/predictions-segmentation/\"),\n",
    "#                       (\"Model_B\", \"../../test-data/localization/predictions-segmentation/\")]\n",
    "\n",
    "# define the problem task (INSTANCE_SEGMENTATION, OBJECT_DETECTION)\n",
    "task_type = TaskType.INSTANCE_SEGMENTATION\n",
    "\n",
    "# [OPTIONAL] define the file_name for the meta-annotations\n",
    "properties_file = \"properties_plane.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_dataset = DatasetLocalization(dataset_gt_param, \n",
    "                                 task_type, \n",
    "                                 proposals_paths=path_to_detections, \n",
    "                                 properties_file=properties_file, \n",
    "                                 save_graphs_as_png=False,\n",
    "                                 for_analysis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload the properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dataset.reload_properties(from_file=False)\n",
    "\n",
    "# If you modify directly the '[properties].json' file\n",
    "# my_dataset.reload_properties(from_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.show_co_occurrence_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_categories()\n",
    "\n",
    "# [OPTIONAL] do not compute also the avg size of the mask/bbox for each category\n",
    "# show_avg_size = False\n",
    "\n",
    "# my_dataset.show_distribution_of_categories(show_avg_size=show_avg_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_properties()\n",
    "\n",
    "# [OPTIONAL] define specific properties to be analyzed\n",
    "# properties_to_be_analyzed = ['weather', 'wing_type']\n",
    "\n",
    "# my_dataset.show_distribution_of_properties(properties=properties_to_be_analyzed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_property('propulsion')\n",
    "\n",
    "# [OPTIONAL] define property values to be included in the analysis\n",
    "# values = [\"jet\", \"propeller\"]\n",
    "\n",
    "# my_dataset.show_distribution_of_property('propulsion', property_values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_property_for_categories('propulsion')\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] define property values to be included in the analysis\n",
    "# values = [\"jet\", \"propeller\"]\n",
    "\n",
    "# my_dataset.show_distribution_of_property_for_categories('propulsion', property_values=values, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.show_distribution_of_property_for_category('propulsion', 'SmallCivilTransportUtility')\n",
    "\n",
    "# [OPTIONAL] define property values to be included in the analysis\n",
    "# values = [\"jet\", \"propeller\"]\n",
    "\n",
    "# my_dataset.show_distribution_of_property_for_category('propulsion', 'SmallCivilTransportUtility', property_values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer = AnalyzerLocalization('my_model', # N.B. the name must be the same of ones in the list of the proposals  \n",
    "                                   my_dataset,\n",
    "                                   use_normalization=True,\n",
    "                                   norm_factor_categories=0.3, \n",
    "                                   metric=Metrics.AVERAGE_PRECISION_INTERPOLATED,\n",
    "                                   save_graphs_as_png=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load custom display names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you change the display names of the categories in the properties file\n",
    "my_dataset.load_categories_display_names()\n",
    "\n",
    "# if you change the display names of the properties in the properties file\n",
    "my_dataset.load_properties_display_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.set_normalization(True, with_properties=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the Intersection Over Union (IoU) threshold and/or the weak IoU threshold\n",
    "\n",
    "# my_analyzer.set_iou_threshold(iou=0.75, iou_weak=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis based on meta-annotations\n",
    "\n",
    "The evaluation metric is computed by considering only ground truth subsets with a specific meta-annotation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_properties()\n",
    "\n",
    "# [OPTIONAL] define only specific properties to be analyzed\n",
    "# meta_annotations = ['weather', 'wing_type']\n",
    "\n",
    "# [OPTIONAL] define only specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'LargeCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# [OPTIONAL] set the split method (by categories or by meta-annotations)\n",
    "# split_by = \"categories\"\n",
    "\n",
    "# my_analyzer.analyze_properties(properties=meta_annotations, categories=categories, metric=eval_metric, split_by=split_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_property(\"weather\")\n",
    "\n",
    "# [OPTIONAL] define only specific values to be analyzed\n",
    "# meta_annotation_values = [\"Snow\", \"Clear Skies\"]\n",
    "\n",
    "# [OPTIONAL] define only specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'LargeCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# [OPTIONAL] set the split method (by categories or by meta-annotations)\n",
    "# split_by = \"categories\"\n",
    "\n",
    "# my_analyzer.analyze_property(\"weather\", possible_values=meta_annotation_values, categories=categories, metric=eval_metric, split_by=split_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_sensitivity_impact_of_properties()\n",
    "\n",
    "# [OPTIONAL] define specific meta-annotations to be included in the analysis\n",
    "# meta_annotations = [\"truncated\", \"weather\", \"propulsion\", \"wing_type\", \"num_engines\"]\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_sensitivity_impact_of_properties(properties=meta_annotations, metric=eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positives errors analysis\n",
    "For each category, FP errors are categorized into \"similar\", \"background\", \"localization\", and \"other\", and the impact of each type of error on the evaluation metric score is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_errors()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_false_positive_errors(categories=categories, metric=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_errors_for_category('SmallCivilTransportUtility')\n",
    "\n",
    "# [OPTIONAL] set the evaluation metric to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_false_positive_errors_for_category('SmallCivilTransportUtility', metric=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_trend()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] define whether the correct detections should be included\n",
    "# include_correct = False\n",
    "\n",
    "# my_analyzer.analyze_false_positive_trend(categories=categories, include_correct_predictions=include_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_positive_trend_for_category(\"SmallCivilTransportUtility\")\n",
    "\n",
    "# [OPTIONAL] define whether the correct detections should be included\n",
    "# include_correct = False\n",
    "\n",
    "# my_analyzer.analyze_false_positive_trend_for_category(\"SmallCivilTransportUtility\", include_correct_predictions=include_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False negatives errors analysis\n",
    "For each category, FN errors are categorized into \"similar\", \"localization\", and \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_negative_errors()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.analyze_false_negative_errors(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_false_negative_errors_for_category(\"LargeCivilTransportUtility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis based on PR curve and F1 curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_curve(average=\"micro\")\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis (default is PRECISION_RECALL_CURVE)\n",
    "# eval_curve = Curves.F1_CURVE \n",
    "\n",
    "# [OPTIONAL] set the averaging method to be used in the analysis (default is \"macro\")\n",
    "# avg_method = \"micro\"\n",
    "\n",
    "# my_analyzer.analyze_curve(curve=eval_curve, average=avg_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_curve_for_categories()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis (default is PRECISION_RECALL_CURVE)\n",
    "# eval_curve = Curves.F1_CURVE \n",
    "\n",
    "# my_analyzer.analyze_curve_for_categories(categories=categories, curve=eval_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis based on IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_intersection_over_union()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_intersection_over_union(categories=categories, metric=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.analyze_intersection_over_union_for_category('SmallCivilTransportUtility')\n",
    "\n",
    "# [OPTIONAL] set the curve to be used in the analysis\n",
    "# eval_metric = Metrics.PRECISION_SCORE\n",
    "\n",
    "# my_analyzer.analyze_intersection_over_union_for_category('SmallCivilTransportUtility', metric=eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_reliability()\n",
    "\n",
    "# [OPTIONAL] define the number of bins for the analysis (default is 10)\n",
    "# bins = 20\n",
    "\n",
    "# my_analyzer.analyze_reliability(num_bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_analyzer.analyze_reliability_for_categories()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] define the number of bins for the analysis (default is 10)\n",
    "# bins = 20\n",
    "\n",
    "# my_analyzer.analyze_reliability_for_categories(categories=categories, num_bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP, FP, FN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_true_positive_distribution()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_true_positive_distribution(categories=categories)\n",
    "\n",
    "#my_analyzer.show_true_positive_distribution(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_false_negative_distribution()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_false_negative_distribution(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_false_positive_distribution()\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_false_positive_distribution(categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per-property distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_true_positive_distribution_for_categories_for_property(\"weather\")\n",
    "\n",
    "# [OPTIONAL] define only specific values to be analyzed\n",
    "# meta_annotation_values = [\"Snow\", \"Clear Skies\"]\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_true_positive_distribution_for_categories_for_property(\"weather\", property_values=meta_annotation_values, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.show_false_negative_distribution_for_categories_for_property(\"weather\")\n",
    "\n",
    "# [OPTIONAL] define only specific values to be analyzed\n",
    "# meta_annotation_values = [\"Snow\", \"Clear Skies\"]\n",
    "\n",
    "# [OPTIONAL] define specific categories to be analyzed\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# my_analyzer.show_false_negative_distribution_for_categories_for_property(\"weather\", property_values=meta_annotation_values, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report of all the performance at all levels of granularity (overall, per-category, per-meta-annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analyzer.base_report()\n",
    "\n",
    "# [OPTIONAL] define specific evaluation metrics to be included in the report\n",
    "# eval_metrics = [Metrics.PRECISION_SCORE, Metrics.F1_SCORE]\n",
    "\n",
    "# [OPTIONAL] define specific categories to be included in the report\n",
    "# categories = ['SmallCivilTransportUtility', 'MediumCivilTransportUtility']\n",
    "\n",
    "# [OPTIONAL] define specific meta-annotations to be included in the report\n",
    "# meta_annotations = [\"weather\", \"wing_type\"]\n",
    "\n",
    "# [OPTIONAL] do not include categories and/or meta-annotations in the report\n",
    "# show_categories = True\n",
    "# show_meta_annotations = True\n",
    "\n",
    "# my_analyzer.base_report(metrics=eval_metrics, categories=categories, properties=meta_annotations, show_categories=show_categories, show_properties=show_meta_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
